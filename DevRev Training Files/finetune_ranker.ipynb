{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers import InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Hard Negatives by training on the bm25 retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bm25scores_new_paras.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_count = []\n",
    "for theme in df[\"Theme\"].unique():\n",
    "    theme_count.append((df.loc[df[\"Theme\"] == theme].shape[0], theme))\n",
    "theme_count.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(212, 'IPod'),\n",
       " (186, '2008_Sichuan_earthquake'),\n",
       " (124, 'Pub'),\n",
       " (104, 'Catalan_language'),\n",
       " (70, 'Adult_contemporary_music'),\n",
       " (50, 'Canadian_Armed_Forces'),\n",
       " (37, 'Cardinal_(Catholicism)'),\n",
       " (34, 'Paper'),\n",
       " (29, 'Heresy'),\n",
       " (26, 'Human_Development_Index')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_count[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_test = pd.DataFrame(columns=df.columns)\n",
    "theme_train = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for theme in df[\"Theme\"].unique():\n",
    "  group = df.loc[df[\"Theme\"] == theme]\n",
    "  group_train, group_test = train_test_split(group, test_size=0.2)\n",
    "  theme_test = pd.concat([theme_test,group_test])\n",
    "  theme_train = pd.concat([theme_train,group_train])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting training args and loading the student and teacher models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "num_epochs = 1\n",
    "model_save_path = 'output/minilml2_mse_12_domain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', num_labels=1, device=\"cuda:3\")\n",
    "student_model = CrossEncoder('output/minilml2_mse_12', num_labels=1, device=\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 944/944 [00:27<00:00, 34.76it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_kd_samples(df):\n",
    "  samples = []\n",
    "  \n",
    "  for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    \n",
    "    teacher_input = []\n",
    "    for i in range(10):\n",
    "      if pd.isnull(row[\"resb_par\" + str(i)]):\n",
    "        continue\n",
    "      teacher_input.append([row['Question'], row[\"resb_par\" + str(i)]])\n",
    "    \n",
    "    if len(teacher_input) == 0:\n",
    "        continue\n",
    "    \n",
    "    ce_logit = teacher_model.predict(teacher_input)\n",
    "    ind = np.argmax(ce_logit)\n",
    "    \n",
    "    if (teacher_input[ind][1] != row[\"Paragraph\"]):\n",
    "      continue\n",
    "      \n",
    "    for i in range(len(ce_logit)):  \n",
    "      samples.append(InputExample(texts=teacher_input[i], label=ce_logit[i]))\n",
    "\n",
    "  return samples\n",
    "\n",
    "X = get_kd_samples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"samples_minilm12\", \"rb\") as fp:   \n",
    "  X = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(X, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(X)\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ade0f6347e343a49eba17886d642681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3f81543d4c4316bf45dd212321e38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student_model.fit(train_dataloader=train_dataloader,\n",
    "          loss_fct=torch.nn.MSELoss(),\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.nodes import SentenceTransformersRanker\n",
    "from haystack.nodes import BM25Retriever\n",
    "from haystack import Document as document\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = SentenceTransformersRanker(model_name_or_path=\"output/minilml2_mse_13\", devices=[\"cuda:1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 194/194 [00:04<00:00, 39.92it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for index, row in tqdm(theme_test.iterrows(), total=theme_test.shape[0]):\n",
    "  filtered_docs = []\n",
    "  for i in range(10):\n",
    "    if pd.isnull(row[\"resb_par\" + str(i)]):\n",
    "      continue\n",
    "    filtered_docs.append(document.from_dict({'content': row[\"resb_par\" + str(i)], 'meta': {'name': row[\"Theme\"]}}))  \n",
    "\n",
    "  if (len(filtered_docs) == 0):\n",
    "    X.append(np.zeros((10, 2)))\n",
    "    y.append(np.zeros((10, )))\n",
    "    continue\n",
    "\n",
    "  sample_res_2 = ranker.predict(\n",
    "      query = row[\"Question\"],\n",
    "      top_k = len(filtered_docs),\n",
    "      documents = filtered_docs\n",
    "  )\n",
    "\n",
    "  scores = {}\n",
    "  gold = {}\n",
    "  for res in sample_res_2:\n",
    "    scores[res.id] = [[res.score]]\n",
    "    gold[res.id] = (1 if res.content == row[\"Paragraph\"] else 0)\n",
    "\n",
    "\n",
    "  _X = np.concatenate(list(scores.values()))\n",
    "  _X = np.pad(_X, [(0, 10 - _X.shape[0]),(0, 0)], \"constant\")\n",
    "  _y = np.array(list(gold.values()))\n",
    "  _y = np.pad(_y, (0, 10 - _y.shape[0]), \"constant\")\n",
    "\n",
    "  X.append(_X)\n",
    "  y.append(_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_predicted_rank():\n",
    "  pos = []\n",
    "  for i in range(len(X)):\n",
    "    _pos = np.argmax(y[i])\n",
    "    if (sum(y[i]) == 0):\n",
    "      pos.append(-1)\n",
    "      continue\n",
    "    pos.append(_pos)\n",
    "    \n",
    "\n",
    "  return pos, Counter(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 155, 1: 16, -1: 13, 2: 6, 4: 2, 3: 2})\n",
      "0.7989690721649485\n"
     ]
    }
   ],
   "source": [
    "pos, count_pos = get_predicted_rank()\n",
    "print(count_pos)\n",
    "print(count_pos[0]/len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 155, 1: 17, -1: 13, 2: 6, 4: 2, 3: 1})\n",
      "0.7989690721649485\n"
     ]
    }
   ],
   "source": [
    "pos, count_pos = get_predicted_rank()\n",
    "print(count_pos)\n",
    "print(count_pos[0]/len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2832, 1: 151, -1: 92, 2: 43, 3: 18, 5: 10, 4: 9, 7: 4, 6: 3, 8: 2, 9: 1})\n",
      "0.8947867298578199\n"
     ]
    }
   ],
   "source": [
    "pos, count_pos = get_predicted_rank()\n",
    "print(count_pos)\n",
    "print(count_pos[0]/len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuned theme overlap split, e = 9\n",
    "# Counter({0: 2855, 1: 142, -1: 76, 2: 39, 3: 18, 4: 11, 5: 10, 6: 6, 7: 4, 9: 3, 8: 1})\n",
    "# 0.9020537124802528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuned theme overlap split, e = 5\n",
    "# Counter({0: 2831, 1: 163, -1: 76, 2: 37, 3: 22, 4: 14, 6: 8, 7: 6, 5: 5, 9: 3})\n",
    "# 0.8944707740916271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuned theme overlap split, e = 3\n",
    "# Counter({0: 2776, 1: 181, -1: 100, 2: 53, 3: 21, 4: 14, 6: 7, 7: 6, 5: 4, 9: 3})\n",
    "# 0.8770932069510269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained theme overlap split\n",
    "# Counter({0: 2706, 1: 209, -1: 100, 2: 63, 3: 33, 4: 25, 6: 9, 5: 8, 7: 4, 8: 4, 9: 4})\n",
    "# 0.8549763033175355"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
